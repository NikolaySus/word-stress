{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5HmwpqzwnMyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'character-tokenizer' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQkp36rEoScR"
   },
   "source": [
    "Задание: обучите модель классификации букв для задачи расстановки ударения с помощью методов из библиотеки transformers. Датасет для обучения можно взять отсюда: https://github.com/Koziev/NLP_Datasets/blob/master/Stress/all_accents.zip\n",
    "\n",
    "1. Напишите класс для Dataset/Dataloder и разбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)\n",
    "2. Попробуйте обучить одну или несколько из моделей: Bert, Albert, Deberta. Посчитайте метрику Accuracy на train и test. (1 балл). При преодолении порога в Accuracy на test 0.8: (+1 балл), 0.85: (+2 балла), 0.89: (+3 балла).\n",
    "Пример конфигурации для deberta: https://huggingface.co/IlyaGusev/ru-word-stress-transformer/blob/main/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pynvml import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-ка</td>\n",
       "      <td>-к^а</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-либо</td>\n",
       "      <td>-л^ибо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-нибудь</td>\n",
       "      <td>-ниб^удь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-с</td>\n",
       "      <td>-с</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-таки</td>\n",
       "      <td>-так^и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680529</th>\n",
       "      <td>ӂюль-верновский</td>\n",
       "      <td>ӂюль-в^ерновский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680530</th>\n",
       "      <td>ӂюрить</td>\n",
       "      <td>ӂюр^ить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680531</th>\n",
       "      <td>ӂӂение</td>\n",
       "      <td>ӂӂ^ение</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680532</th>\n",
       "      <td>ӂӂенный</td>\n",
       "      <td>ӂӂенный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680533</th>\n",
       "      <td>ӂӂеный</td>\n",
       "      <td>ӂӂеный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680534 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     -де              -д^е\n",
       "0                    -ка              -к^а\n",
       "1                  -либо            -л^ибо\n",
       "2                -нибудь          -ниб^удь\n",
       "3                     -с                -с\n",
       "4                  -таки            -так^и\n",
       "...                  ...               ...\n",
       "1680529  ӂюль-верновский  ӂюль-в^ерновский\n",
       "1680530           ӂюрить           ӂюр^ить\n",
       "1680531           ӂӂение           ӂӂ^ение\n",
       "1680532          ӂӂенный           ӂӂенный\n",
       "1680533           ӂӂеный            ӂӂеный\n",
       "\n",
       "[1680534 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"all_accents.tsv\", delimiter=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with '^': 0\n"
     ]
    }
   ],
   "source": [
    "count_without_caret = np.sum(['^' in s for s in df[\"-де\"]])\n",
    "\n",
    "print(\"Number of strings with '^':\", count_without_caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings without '^': 507\n"
     ]
    }
   ],
   "source": [
    "count_without_caret = np.sum(['^' not in s for s in df[\"-д^е\"]])\n",
    "\n",
    "print(\"Number of strings without '^':\", count_without_caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-ка</td>\n",
       "      <td>-к^а</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-либо</td>\n",
       "      <td>-л^ибо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-нибудь</td>\n",
       "      <td>-ниб^удь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-таки</td>\n",
       "      <td>-так^и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-то</td>\n",
       "      <td>-т^о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680527</th>\n",
       "      <td>ѐльцинско-гайдаровский</td>\n",
       "      <td>ѐльцинско-гайд^аровский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680528</th>\n",
       "      <td>ӂен-премьер</td>\n",
       "      <td>ӂен-премь^ер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680529</th>\n",
       "      <td>ӂюль-верновский</td>\n",
       "      <td>ӂюль-в^ерновский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680530</th>\n",
       "      <td>ӂюрить</td>\n",
       "      <td>ӂюр^ить</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680531</th>\n",
       "      <td>ӂӂение</td>\n",
       "      <td>ӂӂ^ение</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680027 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            -де                     -д^е\n",
       "0                           -ка                     -к^а\n",
       "1                         -либо                   -л^ибо\n",
       "2                       -нибудь                 -ниб^удь\n",
       "4                         -таки                   -так^и\n",
       "5                           -то                     -т^о\n",
       "...                         ...                      ...\n",
       "1680527  ѐльцинско-гайдаровский  ѐльцинско-гайд^аровский\n",
       "1680528             ӂен-премьер             ӂен-премь^ер\n",
       "1680529         ӂюль-верновский         ӂюль-в^ерновский\n",
       "1680530                  ӂюрить                  ӂюр^ить\n",
       "1680531                  ӂӂение                  ӂӂ^ение\n",
       "\n",
       "[1680027 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_caret = df[df[\"-д^е\"].str.contains(r'\\^', na=False)]\n",
    "df_with_caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: [' ', ',', '-', '.', '/', ';', '^', '_', 'c', 'g', 'h', '{', '~', '\\xa0', '\\xad', '·', 'ʔ', 'ʕ', '̣', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ѐ', 'і', 'ѣ', 'ӂ', '\\u200e', '\\u200f', '—']\n"
     ]
    }
   ],
   "source": [
    "unique_chars = sorted(set(\"\".join(df_with_caret[\"-д^е\"])))\n",
    "\n",
    "print(\"Unique characters:\", unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лучше ограничиться современным русским алфавитом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-',\n",
       " '^',\n",
       " 'а',\n",
       " 'б',\n",
       " 'в',\n",
       " 'г',\n",
       " 'д',\n",
       " 'е',\n",
       " 'ж',\n",
       " 'з',\n",
       " 'и',\n",
       " 'й',\n",
       " 'к',\n",
       " 'л',\n",
       " 'м',\n",
       " 'н',\n",
       " 'о',\n",
       " 'п',\n",
       " 'р',\n",
       " 'с',\n",
       " 'т',\n",
       " 'у',\n",
       " 'ф',\n",
       " 'х',\n",
       " 'ц',\n",
       " 'ч',\n",
       " 'ш',\n",
       " 'щ',\n",
       " 'ъ',\n",
       " 'ы',\n",
       " 'ь',\n",
       " 'э',\n",
       " 'ю',\n",
       " 'я',\n",
       " '—'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_chars = set(unique_chars[19:51] + ['-', '^', '—'])\n",
    "allowed_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allowed_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-де</th>\n",
       "      <th>-д^е</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-ка</td>\n",
       "      <td>-к^а</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-либо</td>\n",
       "      <td>-л^ибо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-нибудь</td>\n",
       "      <td>-ниб^удь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-таки</td>\n",
       "      <td>-так^и</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-то</td>\n",
       "      <td>-т^о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680436</th>\n",
       "      <td>ящурок</td>\n",
       "      <td>^ящурок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680437</th>\n",
       "      <td>ящуром</td>\n",
       "      <td>^ящуром</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680438</th>\n",
       "      <td>ящуру</td>\n",
       "      <td>^ящуру</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680439</th>\n",
       "      <td>яэль</td>\n",
       "      <td>я^эль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680441</th>\n",
       "      <td>яяло</td>\n",
       "      <td>я^яло</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1674654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             -де      -д^е\n",
       "0            -ка      -к^а\n",
       "1          -либо    -л^ибо\n",
       "2        -нибудь  -ниб^удь\n",
       "4          -таки    -так^и\n",
       "5            -то      -т^о\n",
       "...          ...       ...\n",
       "1680436   ящурок   ^ящурок\n",
       "1680437   ящуром   ^ящуром\n",
       "1680438    ящуру    ^ящуру\n",
       "1680439     яэль     я^эль\n",
       "1680441     яяло     я^яло\n",
       "\n",
       "[1674654 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_with_caret[df_with_caret[\"-д^е\"].apply(lambda s: all(char in allowed_chars for char in s))]\n",
    "\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Потери небольшие, зато везде есть ударение и нет ненужных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] - df_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-^абвгдежзийклмнопрстуфхцчшщъыьэюя—'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ''.join(sorted(\"\".join(allowed_chars)))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import sys\n",
    "sys.path.append(\"/content/character-tokenizer\")\n",
    "from charactertokenizer import CharacterTokenizer\n",
    "\n",
    "model_max_length = 64\n",
    "tokenizer = CharacterTokenizer(chars, model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 24, 25, 17, 11, 14, 27, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "example = \"привет\"\n",
    "tokens = tokenizer(example)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df_filtered[\"-де\"].values\n",
    "words_with_stress = df_filtered[\"-д^е\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  -ка\n",
      "Tokenized:  ['-', 'к', 'а']\n",
      "Token IDs:  [7, 19, 9]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', words[0])\n",
    "\n",
    "print('Tokenized: ', tokenizer.tokenize(words[0]))\n",
    "\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(words[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max word length:  58\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "for word in words:\n",
    "\n",
    "    input_ids = tokenizer.encode(word, add_special_tokens=True)\n",
    "\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max word length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  -ка\n",
      "Original with stress:  -к^а\n",
      "Token IDs: tensor([ 0,  7, 19,  9,  1,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4])\n",
      "Mask:  tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Label: tensor(3)\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 60\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "labels = []\n",
    "for inp, out in zip(words, words_with_stress):\n",
    "    tokenized = tokenizer.encode_plus(\n",
    "        inp,\n",
    "        truncation = True,            # Truncate all words.\n",
    "        add_special_tokens = True,\n",
    "        max_length = MAX_LENGTH,      # Pad/Truncate all words.\n",
    "        padding = 'max_length',       # Pad all words.\n",
    "        return_attention_mask = True, # Construct attn. masks.\n",
    "        return_tensors = 'pt',        # Return pytorch tensors.\n",
    "    )\n",
    "    \n",
    "    token_labels = torch.tensor([out.index(\"^\") + 1], dtype=int)\n",
    "    labels.append(token_labels)\n",
    "    \n",
    "    # Add the encoded word to the list.\n",
    "    input_ids.append(tokenized['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(tokenized['attention_mask'])\n",
    "    assert token_labels[0]<60, \"target: {} invalid\".format(target)\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.cat(labels, dim=0)\n",
    "\n",
    "print('Original: ', words[0])\n",
    "print('Original with stress: ', words_with_stress[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Mask: ', attention_masks[0])\n",
    "print('Label:', labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Напишите класс для Dataset/Dataloder и разбейте данные на случайные train / test сплиты в соотношении 50:50. (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamedTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors, names):\n",
    "        \"\"\"\n",
    "        Initialize the NamedTensorDataset.\n",
    "\n",
    "        Args:\n",
    "            *tensors: Tensors to be stored in the dataset.\n",
    "            names (tuple): A tuple of strings representing the names of the tensors.\n",
    "        \"\"\"\n",
    "        if len(tensors) != len(names):\n",
    "            raise ValueError(\"Number of tensors and number of names must be the same.\")\n",
    "        for tensor in tensors:\n",
    "            if not isinstance(tensor, torch.Tensor):\n",
    "                raise TypeError(\"All inputs must be torch.Tensors.\")\n",
    "            if tensors[0].size(0) != tensor.size(0):\n",
    "                raise ValueError(\"All tensors must have the same size in the first dimension.\")\n",
    "        self.tensors = tensors\n",
    "        self.names = names\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Retrieve a single item from the dataset.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary mapping names to the corresponding tensor values for the given index.\n",
    "        \"\"\"\n",
    "        return {name: tensor[index] for name, tensor in zip(self.names, self.tensors)}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837,327 training samples\n",
      "837,327 validation samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = NamedTensorDataset(input_ids, attention_masks, labels, names=('input_ids', 'attention_masks', 'labels'))\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попробуйте обучить одну или несколько из моделей: Bert, Albert, Deberta. Посчитайте метрику Accuracy на train и test. (1 балл). При преодолении порога в Accuracy на test 0.8: (+1 балл), 0.85: (+2 балла), 0.89: (+3 балла). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaV2Config, DebertaV2ForSequenceClassification\n",
    "import evaluate\n",
    "\n",
    "config = DebertaV2Config.from_json_file(\"config.json\")\n",
    "model = DebertaV2ForSequenceClassification(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(41, 256, padding_idx=0)\n",
       "      (position_embeddings): Embedding(60, 256)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(120, 256)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=256, out_features=60, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mRVK6TNAZQFk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The speedups for torchdynamo mostly come wih GPU Ampere or higher and which is not detected here.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",          # Directory to save model checkpoints\n",
    "    overwrite_output_dir=True,           # Overwrite content in the output directory\n",
    "    eval_strategy=\"epoch\",                # Evaluate after each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-4,                    # Learning rate for training\n",
    "    per_device_train_batch_size=batch_size, # Batch size per device\n",
    "    per_device_eval_batch_size=batch_size,  # Batch size per device\n",
    "    num_train_epochs=77,                   # Total number of epochs\n",
    "    weight_decay=1e-4,                    # Weight decay for regularization\n",
    "    save_steps=10000,                    # Save checkpoint every 10000 steps\n",
    "    save_total_limit=10,                 # Keep only the last 10 checkpoints\n",
    "    logging_dir=\"./logs\",                # Directory for logs\n",
    "    logging_steps=10000,                 # Log every 10000 steps\n",
    "    load_best_model_at_end=True,\n",
    "    torch_compile=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82674/2124374710.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                          # Model to train\n",
    "    args=training_args,                   # Training configuration\n",
    "    train_dataset=train_dataset,          # Training dataset\n",
    "    eval_dataset=test_dataset,            # Evaluation dataset\n",
    "    tokenizer=tokenizer,                  # Tokenizer for alignment (optional)\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='62986' max='62986' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [62986/62986 6:16:34, Epoch 77/77]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.829358</td>\n",
       "      <td>0.691770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674275</td>\n",
       "      <td>0.740037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.616466</td>\n",
       "      <td>0.757649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.571214</td>\n",
       "      <td>0.773046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.550709</td>\n",
       "      <td>0.779365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.519151</td>\n",
       "      <td>0.792757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.490125</td>\n",
       "      <td>0.801892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.477384</td>\n",
       "      <td>0.807121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.466689</td>\n",
       "      <td>0.812059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.460778</td>\n",
       "      <td>0.814420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.439068</td>\n",
       "      <td>0.822079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.431164</td>\n",
       "      <td>0.826420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.421466</td>\n",
       "      <td>0.831084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.400760</td>\n",
       "      <td>0.838129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.388496</td>\n",
       "      <td>0.843250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.396820</td>\n",
       "      <td>0.842063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.379804</td>\n",
       "      <td>0.847494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.364599</td>\n",
       "      <td>0.854291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.366066</td>\n",
       "      <td>0.854347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.359892</td>\n",
       "      <td>0.858762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.347069</td>\n",
       "      <td>0.862325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.337534</td>\n",
       "      <td>0.868173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.341724</td>\n",
       "      <td>0.867290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.329794</td>\n",
       "      <td>0.870877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.321649</td>\n",
       "      <td>0.874829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.307406</td>\n",
       "      <td>0.880337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.303490</td>\n",
       "      <td>0.881380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>0.883517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.292283</td>\n",
       "      <td>0.886675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.284229</td>\n",
       "      <td>0.889636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.281054</td>\n",
       "      <td>0.891644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.282238</td>\n",
       "      <td>0.893079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.277606</td>\n",
       "      <td>0.893300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.270635</td>\n",
       "      <td>0.897359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.264173</td>\n",
       "      <td>0.898786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.270503</td>\n",
       "      <td>0.898047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.256031</td>\n",
       "      <td>0.903089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.254375</td>\n",
       "      <td>0.904255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.251962</td>\n",
       "      <td>0.905913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.253226</td>\n",
       "      <td>0.905103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.906149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.249020</td>\n",
       "      <td>0.907350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.243006</td>\n",
       "      <td>0.910387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.239022</td>\n",
       "      <td>0.911510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.241672</td>\n",
       "      <td>0.911559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.238012</td>\n",
       "      <td>0.912039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.227567</td>\n",
       "      <td>0.916618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.305400</td>\n",
       "      <td>0.231041</td>\n",
       "      <td>0.915359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.231858</td>\n",
       "      <td>0.915038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.226473</td>\n",
       "      <td>0.917465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.228971</td>\n",
       "      <td>0.916259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.226299</td>\n",
       "      <td>0.917539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.223287</td>\n",
       "      <td>0.919299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.221610</td>\n",
       "      <td>0.921043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.218823</td>\n",
       "      <td>0.921450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.221224</td>\n",
       "      <td>0.920607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.215451</td>\n",
       "      <td>0.922638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.215283</td>\n",
       "      <td>0.922788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.219193</td>\n",
       "      <td>0.922033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.220818</td>\n",
       "      <td>0.921744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>0.214252</td>\n",
       "      <td>0.923834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.211920</td>\n",
       "      <td>0.925204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.211717</td>\n",
       "      <td>0.925395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>0.925893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.212110</td>\n",
       "      <td>0.925601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.207940</td>\n",
       "      <td>0.927372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.210464</td>\n",
       "      <td>0.926236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.209226</td>\n",
       "      <td>0.927039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.208392</td>\n",
       "      <td>0.927338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.210431</td>\n",
       "      <td>0.926632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.210767</td>\n",
       "      <td>0.926891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.207724</td>\n",
       "      <td>0.928048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.208699</td>\n",
       "      <td>0.927747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.205265</td>\n",
       "      <td>0.928720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.207919</td>\n",
       "      <td>0.928063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.207873</td>\n",
       "      <td>0.928068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.207279</td>\n",
       "      <td>0.928348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=62986, training_loss=0.32351198603099796, metrics={'train_runtime': 22599.5327, 'train_samples_per_second': 2852.899, 'train_steps_per_second': 2.787, 'total_flos': 7.522041536379216e+16, 'train_loss': 0.32351198603099796, 'epoch': 77.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='818' max='818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [818/818 01:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(\"./deberta_stress_model\")\n",
    "tokenizer.save_pretrained(\"./deberta_stress_model\")\n",
    "\n",
    "print(\"Training complete. Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.20526458323001862,\n",
       " 'eval_accuracy': 0.9287196041689806,\n",
       " 'eval_runtime': 97.7454,\n",
       " 'eval_samples_per_second': 8566.408,\n",
       " 'eval_steps_per_second': 8.369,\n",
       " 'epoch': 77.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Порог accuracy в 0.89 пройден. Далее наглядная демонстрация работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beauty_pred(pipe, text):\n",
    "    index = pipe(text)\n",
    "    pos = int(index[0][\"label\"][4:]) - 1\n",
    "    return text[:pos] + '^' + text[pos:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beauty_cmp(dataset, pipe, id):\n",
    "    item = dataset.__getitem__(id)\n",
    "    pos = item['labels'] - 1\n",
    "    text = tokenizer.decode(token_ids=item['input_ids'], skip_special_tokens=True)\n",
    "    print(\"Как правильно:\", text[:pos] + '^' + text[pos:])\n",
    "    print(\" Предсказание:\", beauty_pred(pipe, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как правильно: завздых^ало\n",
      " Предсказание: завздыхал^о\n"
     ]
    }
   ],
   "source": [
    "beauty_cmp(test_dataset, pipe, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как правильно: проводник^овую\n",
      " Предсказание: проводников^ую\n"
     ]
    }
   ],
   "source": [
    "beauty_cmp(test_dataset, pipe, 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как правильно: пл^енум\n",
      " Предсказание: пл^енум\n"
     ]
    }
   ],
   "source": [
    "beauty_cmp(test_dataset, pipe, 4200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как правильно: б^уквочку\n",
      " Предсказание: буквочк^у\n"
     ]
    }
   ],
   "source": [
    "beauty_cmp(test_dataset, pipe, 42000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Как правильно: нар^оем\n",
      " Предсказание: нар^оем\n"
     ]
    }
   ],
   "source": [
    "beauty_cmp(test_dataset, pipe, 420000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
